{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the mathematical formula for a linear SVM?\n",
        "\n",
        "Ans:The mathematical formula for a linear support vector machine (SVM) is wx+b=0. In this equation, w represents the normal vector to the hyperplane\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G0R-YeFyoXrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the objective function of a linear SVM?\n",
        "\n",
        "Ans:the objective function is the geometric margin of the hyperplane (w, b)"
      ],
      "metadata": {
        "id": "IDtvPSDvooZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q3. What is the kernel trick in SVM?\n",
        "\n",
        "Ans:The kernel trick is a powerful technique used in Support Vector Machines (SVMs) to handle non-linear relationships in data by implicitly mapping the data into a higher-dimensional space, where it becomes linearly separable, without explicitly computing the transformation.\n"
      ],
      "metadata": {
        "id": "ePvZZnDZo3R7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is the role of support vectors in SVM Explain with example\n",
        "\n",
        "ans:\n",
        "Support vectors are data points that play a crucial role in the support vector machine (SVM) algorithm by defining the decision boundary and influencing the margin:\n",
        "Defining the decision boundary\n",
        "Support vectors are the data points that are closest to the decision boundary, a hyperplane that separates data points into classes. The SVM uses the support vectors to define the boundary's position.\n",
        "Influencing the margin\n",
        "The distance between the decision boundary and the nearest support vectors is called the margin. The SVM tries to maximize the margin to create a more robust and generalizable model.\n",
        "Predicting class labels\n",
        "Once the support vectors are identified, they are used to predict the class labels of new data points.\n",
        "Improving accuracy\n",
        "The distance between the vectors should be maximized to increase the model's accuracy"
      ],
      "metadata": {
        "id": "hJyp7XG0pEtS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in\n",
        "SVM?\n",
        "Ans:\n",
        "Support Vector Machines (SVMs) aim to find a decision boundary (hyperplane) that maximally separates data points belonging to different classes. In Support Vector Machines (SVMs), the main idea is the margin. The margin signifies the distance between the decision boundary and the closest data points from each class.\n",
        "\n",
        "Maximizing this margin is essential as it provides a measure of robustness against noise and aids in better generalization to unseen data. Two approaches to margins in SVMs are Hard Margin and Soft Margin.\n",
        "\n",
        "Hard Margin SVM\n",
        "In a hard margin SVM, the objective is to identify a hyperplane that completely separates data points belonging to different classes, ensuring a clear demarcation with the utmost margin width possible. This margin is the distance between the hyperplane and the nearest data point, also known as the support vectors.\n",
        "\n",
        "Soft Margin SVM\n",
        "Soft Margin SVM introduces flexibility by allowing some margin violations (misclassifications) to handle cases where the data is not perfectly separable. Suitable for scenarios where the data may contain noise or outliers. It Introduces a penalty term for misclassifications, allowing for a trade-off between a wider margin and a few misclassifications"
      ],
      "metadata": {
        "id": "uqt3RJGCpX2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. SVM Implementation through Iris dataset.\n",
        "\n",
        "Load the iris dataset from the scikit-learn library and split it into a training set and a testing setl\n",
        "~ Train a linear SVM classifier on the training set and predict the labels for the testing setl\n",
        "~ Compute the accuracy of the model on the testing setl\n",
        "~ Plot the decision boundaries of the trained model using two of the featuresl\n",
        "~ Try different values of the regularisation parameter C and see how it affects the performance of\n",
        "the model."
      ],
      "metadata": {
        "id": "A63zldpqp3m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Iris dataset as an example\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Since SVM requires binary classification, we'll consider only two classes\n",
        "X = X[y != 2]\n",
        "y = y[y != 2]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "class LinearSVMFromScratch:\n",
        "    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lambda_param = lambda_param\n",
        "        self.n_iters = n_iters\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0\n",
        "\n",
        "        # Convert labels to -1, 1 if necessary\n",
        "        y = np.where(y <= 0, -1, 1)\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                condition = y[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
        "                if condition:\n",
        "                    self.w -= self.learning_rate * (2 * self.lambda_param * self.w)\n",
        "                else:\n",
        "                    self.w -= self.learning_rate * (2 * self.lambda_param * self.w - np.dot(x_i, y[idx]))\n",
        "                    self.b -= self.learning_rate * y[idx]\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.w) - self.b\n",
        "        return np.sign(linear_output)\n",
        "\n",
        "# Preprocess data: standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train custom linear SVM\n",
        "custom_svm = LinearSVMFromScratch(learning_rate=0.001, lambda_param=0.01, n_iters=1000)\n",
        "custom_svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_custom = custom_svm.predict(X_test_scaled)\n",
        "custom_accuracy = accuracy_score(y_test, y_pred_custom)\n",
        "print(f\"Custom SVM accuracy: {custom_accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsQ6p-X8p9p6",
        "outputId": "e7e5c3ba-5d78-439f-b7e6-30969261a112"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom SVM accuracy: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9qzf_bErKSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}